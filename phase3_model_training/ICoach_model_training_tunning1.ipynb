{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Load the File Directly with Pandas"
      ],
      "metadata": {
        "id": "2olNxxHNjUq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_train_url = 'https://raw.githubusercontent.com/cafrontadoe/laliga-match-prediction/refs/heads/main/phase3_model_training/X_train.csv'\n",
        "X_test_url = 'https://raw.githubusercontent.com/cafrontadoe/laliga-match-prediction/refs/heads/main/phase3_model_training/X_test.csv'\n",
        "y_train_url = 'https://raw.githubusercontent.com/cafrontadoe/laliga-match-prediction/refs/heads/main/phase3_model_training/y_train.csv'\n",
        "y_test_url = 'https://raw.githubusercontent.com/cafrontadoe/laliga-match-prediction/refs/heads/main/phase3_model_training/y_test.csv'\n",
        "\n",
        "X_train: any;\n",
        "X_test: any;\n",
        "y_train: any;\n",
        "y_test: any;\n",
        "\n",
        "try:\n",
        "    # Load X_train\n",
        "    X_train = pd.read_csv(X_train_url)\n",
        "    print(\"X_train loaded successfully.\")\n",
        "\n",
        "    # Load X_test\n",
        "    X_test = pd.read_csv(X_test_url)\n",
        "    print(\"X_test loaded successfully.\")\n",
        "\n",
        "    y_train = pd.read_csv(y_train_url).squeeze()\n",
        "    print(\"y_train loaded successfully.\")\n",
        "\n",
        "    y_test = pd.read_csv(y_test_url).squeeze()\n",
        "    print(\"y_test loaded successfully.\")\n",
        "\n",
        "    print(\"\\nFirst 5 rows of X_train:\")\n",
        "    print(X_train.head())\n",
        "    print(\"\\nFirst 5 values of y_train:\")\n",
        "    print(y_train.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the files: {e}\")\n",
        "    print(\"Please double-check that the URLs are correct and accessible (raw URLs).\")\n",
        "    print(\"Also, ensure the files are truly public and the URLs point to the raw content, not the HTML page.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb2YO7izjY4V",
        "outputId": "1b92e603-6992-438a-f069-0296f4898f70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train loaded successfully.\n",
            "X_test loaded successfully.\n",
            "y_train loaded successfully.\n",
            "y_test loaded successfully.\n",
            "\n",
            "First 5 rows of X_train:\n",
            "   home_avg_goals_scored_last_5  home_avg_goals_conceded_last_5  \\\n",
            "0                           0.0                             0.0   \n",
            "1                           0.0                             0.0   \n",
            "2                           0.0                             0.0   \n",
            "3                           0.0                             0.0   \n",
            "4                           0.0                             0.0   \n",
            "\n",
            "   home_win_rate_last_5  home_draw_rate_last_5  home_loss_rate_last_5  \\\n",
            "0                   0.0                    0.0                    0.0   \n",
            "1                   0.0                    0.0                    0.0   \n",
            "2                   0.0                    0.0                    0.0   \n",
            "3                   0.0                    0.0                    0.0   \n",
            "4                   0.0                    0.0                    0.0   \n",
            "\n",
            "   away_avg_goals_scored_last_5  away_avg_goals_conceded_last_5  \\\n",
            "0                           0.0                             0.0   \n",
            "1                           0.0                             0.0   \n",
            "2                           0.0                             0.0   \n",
            "3                           0.0                             0.0   \n",
            "4                           0.0                             0.0   \n",
            "\n",
            "   away_win_rate_last_5  away_draw_rate_last_5  away_loss_rate_last_5  ...  \\\n",
            "0                   0.0                    0.0                    0.0  ...   \n",
            "1                   0.0                    0.0                    0.0  ...   \n",
            "2                   0.0                    0.0                    0.0  ...   \n",
            "3                   0.0                    0.0                    0.0  ...   \n",
            "4                   0.0                    0.0                    0.0  ...   \n",
            "\n",
            "   away_Real Sociedad  away_Real Valladolid  away_SD Eibar  away_SD Huesca  \\\n",
            "0               False                 False          False           False   \n",
            "1               False                 False           True           False   \n",
            "2               False                 False          False           False   \n",
            "3               False                 False          False           False   \n",
            "4               False                 False          False           False   \n",
            "\n",
            "   away_Sevilla FC  away_Sporting Gijón  away_UD Almería  away_UD Las Palmas  \\\n",
            "0            False                False            False               False   \n",
            "1            False                False            False               False   \n",
            "2            False                False            False               False   \n",
            "3            False                False            False               False   \n",
            "4            False                False            False               False   \n",
            "\n",
            "   away_Valencia  away_Villarreal  \n",
            "0          False            False  \n",
            "1          False            False  \n",
            "2          False            False  \n",
            "3          False             True  \n",
            "4          False            False  \n",
            "\n",
            "[5 rows x 70 columns]\n",
            "\n",
            "First 5 values of y_train:\n",
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: match_result_encoded, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "Q9XX2_D0kC50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scales features to a specific range, usually 0 to 1). StandardScaler is a good general choice"
      ],
      "metadata": {
        "id": "83tZno7NkHLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numerical columns for scaling\n",
        "# Assuming columns like 'home_team_goal', 'away_team_goal', and the 'avg_goals'/'win_rate' stats are numerical.\n",
        "# The 'False'/'True' columns (one-hot encoded teams) should NOT be scaled.\n",
        "# Let's assume all columns NOT starting with 'home_' or 'away_' and are not boolean are numerical.\n",
        "\n",
        "# For demonstration, let's assume all columns in X are numerical except the boolean ones.\n",
        "# You might need to adjust this based on your actual feature set.\n",
        "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "# If you have boolean columns that were created from one-hot encoding, they will be of dtype 'bool'.\n",
        "# You should exclude them from scaling.\n",
        "boolean_cols = X_train.select_dtypes(include=['bool']).columns\n",
        "\n",
        "# Columns to scale: all numerical columns that are not boolean\n",
        "cols_to_scale = [col for col in numerical_cols if col not in boolean_cols]\n",
        "\n",
        "print(\"cols_to_scale\", cols_to_scale);\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data's numerical columns\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
        "\n",
        "# Transform the test data using the *fitted* scaler\n",
        "X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
        "\n",
        "print(\"\\n--- Feature Scaling ---\")\n",
        "print(\"First 5 rows of X_train_scaled (features after scaling):\")\n",
        "print(X_train_scaled.head())\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdcspVS2kRX3",
        "outputId": "89f16bf2-f54d-4287-a48d-258ed1451a3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cols_to_scale ['home_avg_goals_scored_last_5', 'home_avg_goals_conceded_last_5', 'home_win_rate_last_5', 'home_draw_rate_last_5', 'home_loss_rate_last_5', 'away_avg_goals_scored_last_5', 'away_avg_goals_conceded_last_5', 'away_win_rate_last_5', 'away_draw_rate_last_5', 'away_loss_rate_last_5']\n",
            "\n",
            "--- Feature Scaling ---\n",
            "First 5 rows of X_train_scaled (features after scaling):\n",
            "   home_avg_goals_scored_last_5  home_avg_goals_conceded_last_5  \\\n",
            "0                     -1.924194                       -2.087476   \n",
            "1                     -1.924194                       -2.087476   \n",
            "2                     -1.924194                       -2.087476   \n",
            "3                     -1.924194                       -2.087476   \n",
            "4                     -1.924194                       -2.087476   \n",
            "\n",
            "   home_win_rate_last_5  home_draw_rate_last_5  home_loss_rate_last_5  \\\n",
            "0             -1.440168              -1.273225               -1.53813   \n",
            "1             -1.440168              -1.273225               -1.53813   \n",
            "2             -1.440168              -1.273225               -1.53813   \n",
            "3             -1.440168              -1.273225               -1.53813   \n",
            "4             -1.440168              -1.273225               -1.53813   \n",
            "\n",
            "   away_avg_goals_scored_last_5  away_avg_goals_conceded_last_5  \\\n",
            "0                     -1.960848                       -2.082226   \n",
            "1                     -1.960848                       -2.082226   \n",
            "2                     -1.960848                       -2.082226   \n",
            "3                     -1.960848                       -2.082226   \n",
            "4                     -1.960848                       -2.082226   \n",
            "\n",
            "   away_win_rate_last_5  away_draw_rate_last_5  away_loss_rate_last_5  ...  \\\n",
            "0             -1.507242              -1.290863              -1.482409  ...   \n",
            "1             -1.507242              -1.290863              -1.482409  ...   \n",
            "2             -1.507242              -1.290863              -1.482409  ...   \n",
            "3             -1.507242              -1.290863              -1.482409  ...   \n",
            "4             -1.507242              -1.290863              -1.482409  ...   \n",
            "\n",
            "   away_Real Sociedad  away_Real Valladolid  away_SD Eibar  away_SD Huesca  \\\n",
            "0               False                 False          False           False   \n",
            "1               False                 False           True           False   \n",
            "2               False                 False          False           False   \n",
            "3               False                 False          False           False   \n",
            "4               False                 False          False           False   \n",
            "\n",
            "   away_Sevilla FC  away_Sporting Gijón  away_UD Almería  away_UD Las Palmas  \\\n",
            "0            False                False            False               False   \n",
            "1            False                False            False               False   \n",
            "2            False                False            False               False   \n",
            "3            False                False            False               False   \n",
            "4            False                False            False               False   \n",
            "\n",
            "   away_Valencia  away_Villarreal  \n",
            "0          False            False  \n",
            "1          False            False  \n",
            "2          False            False  \n",
            "3          False             True  \n",
            "4          False            False  \n",
            "\n",
            "[5 rows x 70 columns]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Selection &  Model Training\n",
        "###Logistic Regression model & Random forest"
      ],
      "metadata": {
        "id": "c_00pxielgXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from xgboost import XGBClassifier # You'd need to install xgboost: pip install xgboost\n",
        "\n",
        "# --- Logistic Regression ---\n",
        "print(\"\\n--- Model Training (Logistic Regression) ---\")\n",
        "# Initialize the Logistic Regression model\n",
        "# max_iter is increased for convergence, solver can be 'liblinear' for small datasets or 'lbfgs' for larger ones\n",
        "# multi_class='multinomial' is for true multi-class problems (default for 'lbfgs')\n",
        "log_reg_model = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs', multi_class='multinomial')\n",
        "\n",
        "# Train the model\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "print(\"Logistic Regression model trained successfully.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Random Forest Classifier (Another option) ---\n",
        "print(\"\\n--- Model Training (Random Forest Classifier) ---\")\n",
        "# Initialize the Random Forest model\n",
        "# n_estimators is the number of trees, random_state for reproducibility\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 uses all available cores\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "print(\"Random Forest Classifier model trained successfully.\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvwZmrtxlqRY",
        "outputId": "1f4c2547-e91c-4666-9d24-baaa399cd2dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training (Logistic Regression) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Model Training (Random Forest Classifier) ---\n",
            "Random Forest Classifier model trained successfully.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "Zik62T44mARj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "# --- Evaluate Logistic Regression Model ---\n",
        "print(\"\\n--- Evaluating Logistic Regression Model ---\")\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_log_reg = log_reg_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_log_reg:.4f}\")\n",
        "\n",
        "# Display Classification Report\n",
        "print(\"\\nLogistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Display Confusion Matrix\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
        "# The labels for your 'match_result_encoded' are:\n",
        "# 0: Away Win\n",
        "# 1: Draw\n",
        "# 2: Home Win\n",
        "# Adjust if your encoding is different.\n",
        "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
        "print(conf_matrix_log_reg)\n",
        "# You can also visualize this with seaborn.heatmap for better readability\n",
        "\n",
        "# --- Evaluate Random Forest Model ---\n",
        "print(\"\\n--- Evaluating Random Forest Classifier Model ---\")\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
        "\n",
        "# Display Classification Report\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Display Confusion Matrix\n",
        "print(\"\\nRandom Forest Confusion Matrix:\")\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(conf_matrix_rf)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Optional: Predict probabilities (useful for calibration or custom thresholds)\n",
        "# y_proba_log_reg = log_reg_model.predict_proba(X_test_scaled)\n",
        "# y_proba_rf = rf_model.predict_proba(X_test_scaled)\n",
        "# print(\"\\nFirst 5 predicted probabilities (Logistic Regression):\")\n",
        "# print(y_proba_log_reg[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEsiU5EmDjf",
        "outputId": "abcde081-d2b2-4550-9b4b-d4ea25f11412"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Logistic Regression Model ---\n",
            "Logistic Regression Accuracy: 0.5190\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.83      0.65       304\n",
            "           1       0.34      0.07      0.12       184\n",
            "           2       0.51      0.46      0.49       196\n",
            "\n",
            "    accuracy                           0.52       684\n",
            "   macro avg       0.46      0.45      0.42       684\n",
            "weighted avg       0.48      0.52      0.46       684\n",
            "\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[252  14  38]\n",
            " [124  13  47]\n",
            " [ 95  11  90]]\n",
            "\n",
            "--- Evaluating Random Forest Classifier Model ---\n",
            "Random Forest Accuracy: 0.5058\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.83      0.65       304\n",
            "           1       0.29      0.09      0.13       184\n",
            "           2       0.49      0.39      0.44       196\n",
            "\n",
            "    accuracy                           0.51       684\n",
            "   macro avg       0.44      0.44      0.41       684\n",
            "weighted avg       0.46      0.51      0.45       684\n",
            "\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            "[[253  15  36]\n",
            " [123  16  45]\n",
            " [ 95  24  77]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Augmentation (SMOTE) for DRAW\n"
      ],
      "metadata": {
        "id": "nChP1TXW4_ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQtyJxW65CkM",
        "outputId": "7e274d1d-796c-4f4d-834a-84ab454afe49"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline # Use imblearn's Pipeline for resampling steps\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN # A combination of SMOTE and Edited Nearest Neighbours\n",
        "\n",
        "# --- Assume X_train, X_test, y_train, y_test are already loaded/defined ---\n",
        "# (e.g., from your 'split_data' directory)\n",
        "# input_dir = 'split_data'\n",
        "# X_train = pd.read_parquet(os.path.join(input_dir, 'X_train.parquet'))\n",
        "# X_test = pd.read_parquet(os.path.join(input_dir, 'X_test.parquet'))\n",
        "# y_train = pd.read_parquet(os.path.join(input_dir, 'y_train.parquet'))['match_result_encoded']\n",
        "# y_test = pd.read_parquet(os.path.join(input_dir, 'y_test.parquet'))['match_result_encoded']\n",
        "\n",
        "print(\"Data loaded. Proceeding with scaling and SMOTE integration.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Define Numerical Columns for Scaling ---\n",
        "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# --- TimeSeriesSplit for Cross-Validation ---\n",
        "tscv = TimeSeriesSplit(n_splits=5) # Adjust n_splits as needed\n",
        "\n",
        "# --- 1. Random Forest with SMOTE in a Pipeline ---\n",
        "print(\"\\n--- Tuning Random Forest with SMOTE ---\")\n",
        "\n",
        "# Define the pipeline steps: Scaling -> SMOTE -> Classifier\n",
        "# SMOTE is applied *after* scaling within the pipeline\n",
        "pipeline_rf_smote = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('oversampler', SMOTE(random_state=42)), # You can also try SMOTEENN or SMOTETomek\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "# You can tune SMOTE parameters (e.g., k_neighbors) and classifier parameters\n",
        "param_grid_rf_smote = {\n",
        "    'oversampler__k_neighbors': [3, 5, 7], # Number of nearest neighbors for SMOTE\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5],\n",
        "    # 'classifier__class_weight': [None, 'balanced'] # You can still try class_weight with SMOTE\n",
        "}\n",
        "\n",
        "grid_search_rf_smote = GridSearchCV(\n",
        "    pipeline_rf_smote,\n",
        "    param_grid_rf_smote,\n",
        "    cv=tscv, # Use TimeSeriesSplit\n",
        "    scoring='f1_weighted', # Use f1_weighted to balance all classes, or 'accuracy'\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the pipeline on the original (unscaled) X_train and y_train\n",
        "# The pipeline handles scaling and SMOTE internally for each fold\n",
        "grid_search_rf_smote.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for Random Forest with SMOTE: {grid_search_rf_smote.best_params_}\")\n",
        "print(f\"Best cross-validation score (Random Forest with SMOTE): {grid_search_rf_smote.best_score_:.4f}\")\n",
        "\n",
        "best_rf_smote_model = grid_search_rf_smote.best_estimator_\n",
        "y_pred_rf_smote = best_rf_smote_model.predict(X_test) # Predict on original X_test, pipeline handles scaling\n",
        "\n",
        "print(\"\\n--- Evaluated Tuned Random Forest Model with SMOTE ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf_smote):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf_smote))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf_smote))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 2. XGBoost with SMOTE in a Pipeline (Optional, but powerful) ---\n",
        "print(\"\\n--- Tuning XGBoost with SMOTE ---\")\n",
        "\n",
        "pipeline_xgb_smote = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('oversampler', SMOTE(random_state=42)),\n",
        "    ('classifier', XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss',\n",
        "                                 use_label_encoder=False, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_grid_xgb_smote = {\n",
        "    'oversampler__k_neighbors': [3, 5],\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [3, 5, 7],\n",
        "    'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
        "    # 'classifier__scale_pos_weight': [1, 2] # More complex with multi-class, often better to use sample_weight or SMOTE\n",
        "}\n",
        "\n",
        "grid_search_xgb_smote = GridSearchCV(\n",
        "    pipeline_xgb_smote,\n",
        "    param_grid_xgb_smote,\n",
        "    cv=tscv,\n",
        "    scoring='f1_weighted', # Or 'accuracy'\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_search_xgb_smote.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for XGBoost with SMOTE: {grid_search_xgb_smote.best_params_}\")\n",
        "print(f\"Best cross-validation score (XGBoost with SMOTE): {grid_search_xgb_smote.best_score_:.4f}\")\n",
        "\n",
        "best_xgb_smote_model = grid_search_xgb_smote.best_estimator_\n",
        "y_pred_xgb_smote = best_xgb_smote_model.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Evaluated Tuned XGBoost Model with SMOTE ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb_smote):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb_smote))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb_smote))\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q3cIoHp8wCg",
        "outputId": "56aed0b2-e75d-4d71-8141-3ce0be7fac0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded. Proceeding with scaling and SMOTE integration.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Tuning Random Forest with SMOTE ---\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "\n",
            "Best parameters for Random Forest with SMOTE: {'classifier__max_depth': 10, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'oversampler__k_neighbors': 5}\n",
            "Best cross-validation score (Random Forest with SMOTE): 0.4606\n",
            "\n",
            "--- Evaluated Tuned Random Forest Model with SMOTE ---\n",
            "Accuracy: 0.5102\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.75      0.66       304\n",
            "           1       0.34      0.22      0.26       184\n",
            "           2       0.46      0.42      0.44       196\n",
            "\n",
            "    accuracy                           0.51       684\n",
            "   macro avg       0.46      0.46      0.45       684\n",
            "weighted avg       0.48      0.51      0.49       684\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[227  35  42]\n",
            " [ 91  40  53]\n",
            " [ 70  44  82]]\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Tuning XGBoost with SMOTE ---\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [16:16:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters for XGBoost with SMOTE: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'oversampler__k_neighbors': 5}\n",
            "Best cross-validation score (XGBoost with SMOTE): 0.4644\n",
            "\n",
            "--- Evaluated Tuned XGBoost Model with SMOTE ---\n",
            "Accuracy: 0.4883\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.73      0.64       304\n",
            "           1       0.28      0.17      0.22       184\n",
            "           2       0.46      0.40      0.43       196\n",
            "\n",
            "    accuracy                           0.49       684\n",
            "   macro avg       0.43      0.44      0.43       684\n",
            "weighted avg       0.46      0.49      0.46       684\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[223  38  43]\n",
            " [101  32  51]\n",
            " [ 74  43  79]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## refine the Random Forest tuning"
      ],
      "metadata": {
        "id": "o8lwtTk3BWN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"Data loaded. Proceeding with more refined tuning.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Define Numerical Columns for Scaling\n",
        "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# TimeSeriesSplit for Cross-Validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# --- Refined Random Forest with SMOTE in a Pipeline ---\n",
        "print(\"\\n--- Refined Tuning Random Forest with SMOTE ---\")\n",
        "\n",
        "pipeline_rf_smote_refined = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('oversampler', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Refined parameter grid based on previous best results\n",
        "# Focus on values around the previous best ('classifier__max_depth': 10, 'oversampler__k_neighbors': 5)\n",
        "param_grid_rf_smote_refined = {\n",
        "    'oversampler__k_neighbors': [3, 5, 7], # Keep exploring k_neighbors\n",
        "    'classifier__n_estimators': [150, 200, 250], # Narrow range around 200\n",
        "    'classifier__max_depth': [8, 10, 12], # Narrow range around 10\n",
        "    'classifier__min_samples_split': [2, 3, 5], # Narrow range around 2\n",
        "    'classifier__max_features': ['sqrt', 'log2', 0.8] # Add max_features\n",
        "}\n",
        "\n",
        "grid_search_rf_smote_refined = GridSearchCV(\n",
        "    pipeline_rf_smote_refined,\n",
        "    param_grid_rf_smote_refined,\n",
        "    cv=tscv,\n",
        "    scoring='f1_weighted', # Continue using f1_weighted for balanced evaluation\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_search_rf_smote_refined.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for Refined Random Forest with SMOTE: {grid_search_rf_smote_refined.best_params_}\")\n",
        "print(f\"Best cross-validation score (Refined Random Forest with SMOTE): {grid_search_rf_smote_refined.best_score_:.4f}\")\n",
        "\n",
        "best_rf_smote_refined_model = grid_search_rf_smote_refined.best_estimator_\n",
        "y_pred_rf_smote_refined = best_rf_smote_refined_model.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Evaluated Refined Tuned Random Forest Model with SMOTE ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf_smote_refined):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf_smote_refined))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf_smote_refined))\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcdNYqD1BZYa",
        "outputId": "abdda299-17ff-4986-9ccb-edfaba4c289d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded. Proceeding with more refined tuning.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Refined Tuning Random Forest with SMOTE ---\n",
            "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
          ]
        }
      ]
    }
  ]
}